y1 = sign(W);
y2 = abs(W)-lambda2*gamma;
W = y1*y2;
f = computeLoss(X,y,d,p,alpha,beta,S,lambda1,lambda2,w,W, type,M);
f_lip = f_y + t(g_w)%*%(w-y_w) + 1/2/gamma*norm_vec((w-y_w))^2;
for (m in 1:M){
f_lip = f_lip+t(g_W[,m])%*%(W[,m]-y_W[,m])+1/2/gamma*norm_vec((W[,m]-y_W[,m]))^2;
}
}
loss = cbind(loss, f+lambda2*(sum(abs(w))+sum(sum(abs(W)))));
loss[ncol(loss)];
w_2 = w_1;
w_1 = w;
W_2 = W_1;
W_1 = W;
if (k>1 && abs(loss[ncol(loss)]-loss[ncol(loss)-1])/abs(loss[ncol(loss)])<0.001)# || (loss(end)<0))
break;
}
return(list(w,W))
}
#figure;
#plot(loss);
##################
computeGradient =function(X,y,d,p,alpha,beta,S,lambda1,lambda2,w,W, type,M){
N = nrow(X);
D = ncol(X);
#M = length(unique(d));
g_w = matrix(data = 0,nrow = nrow((w)),ncol = ncol(w))
g_W = matrix(data = 0,nrow = nrow(W),ncol = ncol(W))
g_w <- Matrix(g_w, sparse = TRUE)
g_W <- Matrix(g_W, sparse = TRUE)
if (type=="ls"){
for (m in 1:M){
temp = (2*t(X[as.vector(d==m),]))%*% ((X[as.vector(d==m),]%*%(w+W[,m])-y[d==m]));
g_w = g_w + temp;
g_W[,m] = g_W[,m] + temp;
}
}
for (m in 1:M){
#----------------#####################
g_W[,m] = g_W[,m] + 4*beta*(sum(S[m,])*W[,m]-W%*%S[m,]);
}
g_w = g_w - alpha*p+(2*lambda1)*w;
g_W = g_W + (2*lambda1)*W;
return(list(g_w,g_W))
}
##################################
computeLoss<- function(X,y,d,p,alpha,beta,S,lambda1,lambda2,w,W, type,M){
N = nrow(X);
D = ncol(X);
#M = length(unique(d));
f = 0;
if (type=="ls")
{
for (m in 1:M)
f = f+norm_vec((X[as.vector(d==m),]%*%(w+W[,m])-y[d==m]))^2  # sum((X[d==m,]%*%(w+W[,m])-y[d=m])^2);
}
f = f-alpha*t(p)%*%w;
f = f+lambda1*(sum(w^2)+sum(sum(W^2)));
for (i in 1:M){
for (j in 1:M)
f = f+beta*S[i,j]*sum((W[,i]-W[,j])^2);
}
f
}
norm_vec <- function(x) sqrt(sum(x^2))
MultiDomain(X,y,d,p,alpha,beta,S,lambda1,lambda2, type)
D = ncol(X);
M = length(unique(d));
w = matrix(data = 0,nrow = D,ncol = 1)
W = matrix(data = 0,nrow = D,ncol = M)
X <- Matrix(X, sparse = TRUE)
y <- Matrix(y, sparse = TRUE)
# d <- Matrix(d, sparse = TRUE)
p <- Matrix(p, sparse = TRUE)
S <- Matrix(S, sparse = TRUE)
W <- Matrix(W, sparse = TRUE)
w <- Matrix(w, sparse = TRUE)
w_2 = w;
w_1 = w;
W_2 = W;
W_1 = W;
N = nrow(X);
D = ncol(X);
#M = length(unique(d));
f = 0;
if (type=="ls")
{
for (m in 1:M)
f = f+norm_vec((X[as.vector(d==m),]%*%(w+W[,m])-y[d==m]))^2  # sum((X[d==m,]%*%(w+W[,m])-y[d=m])^2);
}
d
m
d==m
X[as.vector(d==m),]
(w+W[,m])-y[d==m])
(w+W[,m])-y[d==m]
y[d==m]
(w+W[,m])
y
d
y[d==m])
y[d==m]
D = ncol(X);
M = length(unique(d));
w = matrix(data = 0,nrow = D,ncol = 1)
W = matrix(data = 0,nrow = D,ncol = M)
X <- Matrix(X, sparse = TRUE)
# y <- Matrix(y, sparse = TRUE)
# d <- Matrix(d, sparse = TRUE)
p <- Matrix(p, sparse = TRUE)
S <- Matrix(S, sparse = TRUE)
W <- Matrix(W, sparse = TRUE)
w <- Matrix(w, sparse = TRUE)
w_2 = w;
w_1 = w;
W_2 = W;
W_1 = W;
f = computeLoss(X, y, d, p, alpha, beta, S, lambda1, lambda2, w, W, type,M)+lambda2*(sum(abs(w))+sum(sum(abs(W))));
loss=f;
k = 0;
gamma = 1;
N = nrow(X);
D = ncol(X);
#M = length(unique(d));
f = 0;
m=1
y[d==m]
d
m
D = ncol(X);
M = length(unique(d));
w = matrix(data = 0,nrow = D,ncol = 1)
W = matrix(data = 0,nrow = D,ncol = M)
X <- Matrix(X, sparse = TRUE)
y <- Matrix(y, sparse = TRUE)
d <- Matrix(d, sparse = TRUE)
p <- Matrix(p, sparse = TRUE)
S <- Matrix(S, sparse = TRUE)
W <- Matrix(W, sparse = TRUE)
w <- Matrix(w, sparse = TRUE)
w_2 = w;
w_1 = w;
W_2 = W;
W_1 = W;
N = nrow(X);
D = ncol(X);
f = 0;
m=1
d
m
d==m
(d==m)[1]
(d==m)[4]
y[d==m]
MultiDomain  = function(X,y,d,p,alpha,beta,S,lambda1,lambda2, type)
{
D = ncol(X);
M = length(unique(d));
w = matrix(data = 0,nrow = D,ncol = 1)
W = matrix(data = 0,nrow = D,ncol = M)
X <- Matrix(X, sparse = TRUE)
y <- Matrix(y, sparse = TRUE)
d <- Matrix(d, sparse = TRUE)
p <- Matrix(p, sparse = TRUE)
S <- Matrix(S, sparse = TRUE)
W <- Matrix(W, sparse = TRUE)
w <- Matrix(w, sparse = TRUE)
w_2 = w;
w_1 = w;
W_2 = W;
W_1 = W;
f = computeLoss(X, y, d, p, alpha, beta, S, lambda1, lambda2, w, W, type,M)+lambda2*(sum(abs(w))+sum(sum(abs(W))));
loss=f;
k = 0;
gamma = 1;
while  (k<1000 && gamma>10^(-40))
{
k=k+1;
a = k/(k+3);
y_w = (1+a)*w_1 - a*w_2;
#print(y_w)
y_W = (1+a)*W_1 - a*W_2;
output=computeGradient(X, y, d, p, alpha, beta, S, lambda1, lambda2, y_w, y_W, type,M);
g_w=output[[1]]
g_W=output[[2]]
w = y_w - gamma*g_w;
W = y_W - gamma*g_W;
w[abs(w)<=lambda2*gamma]=0;
W[abs(W)<=lambda2*gamma]=0;
y1 = sign(w);
y2 = abs(w)-lambda2*gamma;
w = y1*y2;
y1 = sign(W);
y2 = abs(W)-lambda2*gamma;
W = y1*y2;
##I was here
f = computeLoss(X,y,d,p,alpha,beta,S,lambda1,lambda2,w,W, type,M);
f_y = computeLoss(X,y,d,p,alpha,beta,S,lambda1,lambda2,y_w,y_W, type,M);
f_lip = f_y + t(g_w)%*%(w-y_w) + 1/2/gamma*norm_vec((w-y_w))^2;
for (m in 1:M)
{
f_lip = f_lip+t(g_W[,m])%*%(W[,m]-y_W[,m])+1/2/gamma*norm_vec((W[,m]-y_W[,m]))^2;
#####
}
iter = 0;
while ((f>f_lip)[1] && gamma>10^(-40))
{
iter = iter+1;
gamma = gamma/2;
w = y_w - gamma*g_w;
W = y_W - gamma*g_W;
w[abs(w)<=lambda2*gamma]=0;
W[abs(W)<=lambda2*gamma]=0;
y1 = sign(w);
y2 = abs(w)-lambda2*gamma;
w = y1*y2;
y1 = sign(W);
y2 = abs(W)-lambda2*gamma;
W = y1*y2;
f = computeLoss(X,y,d,p,alpha,beta,S,lambda1,lambda2,w,W, type,M);
f_lip = f_y + t(g_w)%*%(w-y_w) + 1/2/gamma*norm_vec((w-y_w))^2;
for (m in 1:M){
f_lip = f_lip+t(g_W[,m])%*%(W[,m]-y_W[,m])+1/2/gamma*norm_vec((W[,m]-y_W[,m]))^2;
}
}
loss = cbind(loss, f+lambda2*(sum(abs(w))+sum(sum(abs(W)))));
loss[ncol(loss)];
w_2 = w_1;
w_1 = w;
W_2 = W_1;
W_1 = W;
if (k>1 && abs(loss[ncol(loss)]-loss[ncol(loss)-1])/abs(loss[ncol(loss)])<0.001)# || (loss(end)<0))
break;
}
return(list(w,W))
}
#figure;
#plot(loss);
##################
computeGradient =function(X,y,d,p,alpha,beta,S,lambda1,lambda2,w,W, type,M){
N = nrow(X);
D = ncol(X);
#M = length(unique(d));
g_w = matrix(data = 0,nrow = nrow((w)),ncol = ncol(w))
g_W = matrix(data = 0,nrow = nrow(W),ncol = ncol(W))
g_w <- Matrix(g_w, sparse = TRUE)
g_W <- Matrix(g_W, sparse = TRUE)
if (type=="ls"){
for (m in 1:M){
temp = (2*t(X[as.vector(d==m),]))%*% ((X[as.vector(d==m),]%*%(w+W[,m])-y[d==m]));
g_w = g_w + temp;
g_W[,m] = g_W[,m] + temp;
}
}
for (m in 1:M){
#----------------#####################
g_W[,m] = g_W[,m] + 4*beta*(sum(S[m,])*W[,m]-W%*%S[m,]);
}
g_w = g_w - alpha*p+(2*lambda1)*w;
g_W = g_W + (2*lambda1)*W;
return(list(g_w,g_W))
}
##################################
computeLoss<- function(X,y,d,p,alpha,beta,S,lambda1,lambda2,w,W, type,M){
N = nrow(X);
D = ncol(X);
#M = length(unique(d));
f = 0;
if (type=="ls")
{
for (m in 1:M)
f = f+norm_vec((X[as.vector(d==m),]%*%(w+W[,m])-y[d==m]))^2  # sum((X[d==m,]%*%(w+W[,m])-y[d=m])^2);
}
f = f-alpha*t(p)%*%w;
f = f+lambda1*(sum(w^2)+sum(sum(W^2)));
for (i in 1:M){
for (j in 1:M)
f = f+beta*S[i,j]*sum((W[,i]-W[,j])^2);
}
f
}
norm_vec <- function(x) sqrt(sum(x^2))
MultiDomain(X,y,d,p,alpha,beta,S,lambda1,lambda2, type)
y=matrix(c(1,-1,-1,1),nrow=4,ncol=1);
d=matrix(c(1,1,2,2),nrow=4,ncol=1);
p=matrix(c(1,0,-1,0,-1,-1,0,0,1,1,1,0,0,0,1,0,-1,1,1,-1,-1),nrow = 21,ncol = 1);
X=t(matrix(c(1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1),nrow = 21,ncol=4));
alpha=0.3;
beta=0.5;
lambda1=6;
lambda2=0.55;
type="ls";
S=matrix(c(0,0,0,0),nrow = 2,ncol = 2)
S=matrix(c(0,0,0,0),nrow = 2,ncol = 2)
MultiDomain(X,y,d,p,alpha,beta,S,lambda1,lambda2, type)
m1 <- matrix(0, nrow = 1000, ncol = 1000)
m1 <- matrix(0, nrow = 1000, ncol = 400000)
m1 <- matrix(0, nrow = 1000, ncol = 400000,sparse=TRUE)
m1 <- Matrix(0, nrow = 1000, ncol = 400000,sparse=TRUE)
object.size(m1)
A = matrix(rnorm(ORDER^2), nrow=ORDER)
B = matrix(rnorm(ORDER^2), nrow=ORDER)
gpuA = gpuMatrix(A, type="double")
gpuB = gpuMatrix(B, type="double")
require(gpuR)
A = matrix(rnorm(ORDER^2), nrow=ORDER)
B = matrix(rnorm(ORDER^2), nrow=ORDER)
gpuA = gpuMatrix(A, type="double")
gpuB = gpuMatrix(B, type="double")
A = matrix(rnorm(ORDER^2), nrow=ORDER)
B = matrix(rnorm(ORDER^2), nrow=ORDER)
gpuA = gpuMatrix(A, type="double")
gpuB = gpuMatrix(B, type="double")
ORDER = 1024
A = matrix(rnorm(ORDER^2), nrow=ORDER)
B = matrix(rnorm(ORDER^2), nrow=ORDER)
gpuA = gpuMatrix(A, type="double")
gpuB = gpuMatrix(B, type="double")
C = A %*% B
gpuC = gpuA %*% gpuB
A = matrix(rnorm(ORDER^2), nrow=ORDER)
B = matrix(rnorm(ORDER^2), nrow=ORDER)
gpuA = gpuMatrix(A, type="float")
gpuB = gpuMatrix(B, type="float")
C = A %*% B
gpuC = gpuA %*% gpuB
m1 <- Matrix(0, nrow = 1000, ncol = 400000,sparse=TRUE)
gpuA = gpuMatrix(m1, type="double")
gpuA = gpuMatrix(matrix(0, nrow = 1000, ncol = 400000), type="float")
rm(list=ls())
options(stringsAsFactors = FALSE)
setwd("E:/CMSA/Main")
require(data.table)
lex_dt<-function(pos_file="pos.csv",neg_file="neg.csv"){
#get positive lexicons
#pos_lex <- unique(read.csv(pos_file,header = FALSE))
pos_lex <- setDT(unique(read.table(pos_file,header = FALSE,sep = ":",stringsAsFactors = FALSE)))
#pos_lex<-pos_lex[,.(lexicon_name=V1,count=V2)]
pos_lex<-pos_lex[,.(lexicon_name=V1,count=V2)]
pos_val<-rep.int(1, nrow(pos_lex))
pos_lex[,value:=pos_val]
#  pos_lex["value"]<-pos_val
# names(pos_lex)<-c("lexicon_name","count","value")
#get negative lexicons
#neg_lex <- unique(read.csv(neg_file,header = FALSE))
neg_lex <- setDT(unique(read.table(neg_file,header = FALSE,sep = ":",stringsAsFactors = FALSE)))
neg_lex<-neg_lex[,.(lexicon_name=V1,count=V2)]
neg_val<-rep.int(-1, nrow(neg_lex))
neg_lex[,value:=neg_val]
# names(neg_lex)<-c("lexicon_name","count","value")
pos_lex<-pos_lex[!lexicon_name%in%neg_lex[,lexicon_name]]
neg_lex<-neg_lex[!lexicon_name%in%pos_lex[,lexicon_name]]
#Combine positive and negative lexicons to a single dataframe
rbind(pos_lex,neg_lex)
# setdiff(union(unique(lex_dt[value==1,lexicon_name]),unique(lex_dt[value==-1,lexicon_name])),intersect(unique(lex_dt[value==1,lexicon_name]),unique(lex_dt[value==-1,lexicon_name])))
}
removeNA<- function(df){
df[complete.cases(df),]
}
#define the domains
domains<-c("books","dvd","kitchen","electronics")
#create list of domain file names
pos_domains<-paste(domains,"pos",sep = "_")
neg_domains<-paste(domains,"neg",sep = "_")
pos_domains_files<-paste(pos_domains,"review",sep = ".")
neg_domains_files<-paste(neg_domains,"review",sep = ".")
#get all domain lexicons and store into dynamic variables Format: <domain_name>_lex_df
#combined_lexicons<-data.frame(matrix(ncol=3,nrow=1))
for (i in 1:length(domains))
{
combined_lexicons<-lex_dt(pos_domains_files[i],neg_domains_files[i])
combined_lexicons<-combined_lexicons[lexicon_name!=""]
#assign(paste(domains[i],"lex_df",sep="_"),lex_df(pos_domains_files[i],neg_domains_files[i]))
#Clean/Remove NA values
assign(paste(domains[i],"lex_dt",sep="_"),combined_lexicons[complete.cases(combined_lexicons),]) ##
}
#  source(file = "get_lex.r",local = FALSE)
sentiscore<- function(i_ndomain,domains)
{
domain_name<-paste(domains[i_ndomain],"lex_dt",sep="_")
data1<-unique(get(domain_name))[lexicon_name!=""]
posLabel1<-data1[value==1,sum(count)]
negLabel1<-data1[value==-1,sum(count)]
N1<-data1[,sum(count)]
term_freq<-data1[,.(count=sum(count)),by=lexicon_name]
all_terms<-term_freq[,lexicon_name]
pos_data1<-data1[value==1]
pos_term_freq<- pos_data1[,.(count=sum(count)),by=lexicon_name]
neg_data1<-data1[value==-1]
neg_term_freq<- neg_data1[,.(count=sum(count)),by=lexicon_name]
pos_missing_terms<-setdiff(term_freq[,lexicon_name], pos_term_freq[,lexicon_name])
pos_missing_freq<-data.table(lexicon_name=pos_missing_terms,count=N1)
neg_missing_terms<-setdiff(term_freq[,lexicon_name], neg_term_freq[,lexicon_name])
neg_missing_freq<-data.table(lexicon_name=neg_missing_terms,count=N1)
pos_term_freq_n1<- pos_term_freq[,.(lexicon_name,count=count*N1)]
term_freq_posLabel1<-term_freq[,.(lexicon_name,count=count*posLabel1)]
neg_term_freq_n1<- neg_term_freq[,.(lexicon_name,count=count*N1)]
term_freq_negLabel1<-term_freq[,.(lexicon_name,count=count*negLabel1)]
pos_term_freq_n1<-rbind(pos_term_freq_n1,pos_missing_freq)
neg_term_freq_n1<-rbind(neg_term_freq_n1,neg_missing_freq)
#Sort the data tables according to lexicon names
setkey(pos_term_freq_n1,lexicon_name)
setkey(neg_term_freq_n1,lexicon_name)
setkey(term_freq_posLabel1,lexicon_name)
setkey(term_freq_negLabel1,lexicon_name)
s1<-pos_term_freq_n1[,count]/term_freq_posLabel1[,count]
s2<-neg_term_freq_n1[,count]/term_freq_negLabel1[,count]
s1<-log(s1)
#s1[s1==-Inf]<-0
s2<-log(s2)
#s2[s2==-Inf]<-0
s<-s1-s2
return(list(lexicon_name=pos_term_freq_n1[,lexicon_name],score=s))
}
calcSim<-function(data_dt1=books_score,data_dt2=kitchen_score)
{
# data_dt1=kitchen_score;data_dt2=electronics_score
missing_data1<-data.table(lexicon_name=setdiff(data_dt2[,lexicon_name],data_dt1[,lexicon_name]),score=0)
missing_data2<-data.table(lexicon_name=setdiff(data_dt1[,lexicon_name],data_dt2[,lexicon_name]),score=0)
data_dt1<-setkey(rbind(data_dt1,missing_data1),lexicon_name)
data_dt2<-setkey(rbind(data_dt2,missing_data2),lexicon_name)
s1<- t(data_dt1[,score])%*%data_dt2[,score]
s2<-sqrt(sum(data_dt1[,score]^2))*sqrt(sum(data_dt2[,score]^2))
s<-s1/s2;
if(s<0) s<-0
s[1]
}
domains=c("books","dvd","kitchen","electronics")
Domains_index<-1:length(domains)
for(i in 1:length(domains))
{
x<-sentiscore(i,domains)
assign(paste(domains[i],"score",sep = "_"),as.data.table(x))
}
SentiSim<-matrix(data = 0,nrow = length(domains),ncol = length(domains))
for( i in 1:length(domains))
{
for( j in 1:length(domains))
{
if(i<j)
SentiSim[i,j]<-calcSim(get(paste(domains[i],"score",sep = "_")),get(paste(domains[j],"score",sep = "_")))
else if(i==j)
SentiSim[i,j]<-0
else
SentiSim[i,j]<-SentiSim[j,i]
}
}
SentiSim<-(SentiSim>0.5)+0
# computeCost<- function()
{
}
require(XML)
require(data.table)
M<-length(domains)
terms_all_domains<-unique(c(books_score[,lexicon_name],kitchen_score[,lexicon_name],dvd_score[,lexicon_name],electronics_score[,lexicon_name]))
#Dictionary Size
D <- length(terms_all_domains)
pos_xml_files<-paste(pos_domains,"xml",sep = ".")
neg_xml_files<-paste(neg_domains,"xml",sep = ".")
for( i in 1:length(domains))
{
posxmldatatable<-setDT(xmlToDataFrame(pos_xml_files[i],stringsAsFactors = FALSE))
pos_review_text<-setDT(list(posxmldatatable[,review_text]))
negxmldatatable<-setDT(xmlToDataFrame(neg_xml_files[i],stringsAsFactors = FALSE))
neg_review_text<-setDT(list(negxmldatatable[,review_text]))
assign(paste("X",i,sep="_"),rbind.data.frame(  pos_review_text,  neg_review_text))
#assign(paste("X",i,sep="_"),get(paste("X",i,sep="_"))[,review_text])
assign(paste("y",i,sep="_"),c(rep.int(x = 1,times = nrow(posxmldatatable)),rep.int(x = -1,times = nrow(negxmldatatable))))
assign(paste("d",i,sep="_"),c(rep.int(x =i,times = nrow(posxmldatatable)+nrow(negxmldatatable))))
}
# count_matrix<-matrix(data = 0,nrow = 2,ncol = length(terms_all_domains))
# library(stringr)
#for(k in 1:length(terms_all_domains))
{
#  count_matrix[1][k]=str_count(X_1[1], terms_all_domains[k])
}
#xmldatatable <- setDT(xmlToDataFrame("positive.xml"))
#w<-matrix(data = 0,ncol = 1  ,nrow = D)
#W<-matrix(data=0,ncol = M,nrow =D )
#domain_dt<-paste(domains,"lex_dt",sep = "_")
#N<-c();
#for( i in 1:length(domains))
##{
# N<-c(N,nrow(get(domain_dt[i])))
#}
#N<-matrix(N,nrow = length(N))
#maxlen<-max(N)
##X<-matrix("",nrow = maxlen,ncol = M)
#X<-matrix()
#for( i in 1:length(domains))
#{
# cbind(X,c(get(domain_dt[i])[,lexicon_name],rep(NA,maxlen-N[i])))
#}
#X1<-matrix(data = 0,nrow = )
require(quanteda)
X_combined<-rbind(X_1,X_2,X_3,X_4)
d<-c(d_1,d_2,d_3,d_4)
X<-dfm(as.matrix(X_combined),n=1,removePunct = TRUE, removeNumbers = TRUE)
y<-c(y_1,y_2,y_3,y_4)
features<-colnames(X)
library(rJava)
.jinit()
senti<-J("senti")
p<-senti$getsenti(.jarray(features))
ncol(X)
p<-senti$getsenti(.jarray(features))
p
ncol(X)
View(calcSim)
View(books_lex_dt)
View(calcSim)
getwd()
getwd
getwd()
setwd("E:/CMSA/Main")
rtvs::debug_source("E:/CMSA/Main/script.R")
rtvs::debug_source("E:/CMSA/Main/script.R")
rtvs::debug_source("E:/CMSA/Main/script.R")
rtvs::debug_source("E:/CMSA/Main/script.R")
rtvs::debug_source("E:/CMSA/Main/script.R")
X_
X_1
setwd("E:/CMSA/Main")
 require(quanteda)   X_combined<-rbind(X_1,X_2,X_3,X_4)   d<-c(d_1,d_2,d_3,d_4)   X<-dfm(as.matrix(X_combined),n=1,removePunct = TRUE, removeNumbers = TRUE)   y<-c(y_1,y_2,y_3,y_4)   features<-colnames(X)   library(rJava)    .jinit()    senti<-J("senti")    p<-senti$getsenti(.jarray(features))
p
X_
X_1
  alpha=0.3;   beta=0.5;   lambda1=6;   lambda2=0.55;   type="ls";   S<-SentiSim
system.time(MultiDomain( X, y, d, p, alpha, beta, S, lambda1, lambda2, type))
require(Matrix)
require(Matrix)
system.time(MultiDomain( X, y, d, p, alpha, beta, S, lambda1, lambda2, type))
system.time(MultiDomain( X, y, d, p, alpha, beta, S, lambda1, lambda2, type))
system.time(MultiDomain( X, y, d, p, alpha, beta, S, lambda1, lambda2, type))
system.time(MultiDomain( X, y, d, p, alpha, beta, S, lambda1, lambda2, type))
system.time(MultiDomain( X, y, d, p, alpha, beta, S, lambda1, lambda2, type))MultiDomain  = function(X,y,d,p,alpha,beta,S,lambda1,lambda2, type) {   D = ncol(X);   M = length(unique(d));   w = matrix(data = 0,nrow = D,ncol = 1)   W = matrix(data = 0,nrow = D,ncol = M)  # X <- Matrix(X, sparse = TRUE)   #y <- Matrix(y, sparse = TRUE) # d <- Matrix(d, sparse = TRUE) #  p <- Matrix(p, sparse = TRUE) #  S <- Matrix(S, sparse = TRUE) #  W <- Matrix(W, sparse = TRUE) #  w <- Matrix(w, sparse = TRUE)   w_2 = w;   w_1 = w;   W_2 = W;   W_1 = W;   f = computeLoss(X, y, d, p, alpha, beta, S, lambda1, lambda2, w, W, type,M)+lambda2*(sum(abs(w))+sum(sum(abs(W))));   loss=f;   k = 0;   gamma = 1;   while  (k<1000 && gamma>10^(-40))   {     print(k)     k=k+1;     a = k/(k+3);     y_w = (1+a)*w_1 - a*w_2;     #print(y_w)     y_W = (1+a)*W_1 - a*W_2;     output=computeGradient(X, y, d, p, alpha, beta, S, lambda1, lambda2, y_w, y_W, type,M);     g_w=output[[1]]     g_W=output[[2]]     w = y_w - gamma*g_w;     W = y_W - gamma*g_W;     w[abs(w)<=lambda2*gamma]=0;     W[abs(W)<=lambda2*gamma]=0;     y1 = sign(w);     y2 = abs(w)-lambda2*gamma;     w = y1*y2;     y1 = sign(W);     y2 = abs(W)-lambda2*gamma;     W = y1*y2;     ##I was here     f = computeLoss(X,y,d,p,alpha,beta,S,lambda1,lambda2,w,W, type,M);     f_y = computeLoss(X,y,d,p,alpha,beta,S,lambda1,lambda2,y_w,y_W, type,M);     f_lip = f_y + t(g_w)%*%(w-y_w) + 1/2/gamma*norm_vec((w-y_w))^2;     for (m in 1:M)     {       f_lip = f_lip+t(g_W[,m])%*%(W[,m]-y_W[,m])+1/2/gamma*norm_vec((W[,m]-y_W[,m]))^2;       #####     }     iter = 0;     while ((f>f_lip)[1] && gamma>10^(-40))     {       iter = iter+1;       gamma = gamma/2;       w = y_w - gamma*g_w;       W = y_W - gamma*g_W;       w[abs(w)<=lambda2*gamma]=0;       W[abs(W)<=lambda2*gamma]=0;       y1 = sign(w);       y2 = abs(w)-lambda2*gamma;       w = y1*y2;       y1 = sign(W);       y2 = abs(W)-lambda2*gamma;       W = y1*y2;       f = computeLoss(X,y,d,p,alpha,beta,S,lambda1,lambda2,w,W, type,M);       f_lip = f_y + t(g_w)%*%(w-y_w) + 1/2/gamma*norm_vec((w-y_w))^2;       for (m in 1:M){         f_lip = f_lip+t(g_W[,m])%*%(W[,m]-y_W[,m])+1/2/gamma*norm_vec((W[,m]-y_W[,m]))^2;       }     }     loss = cbind(loss, f+lambda2*(sum(abs(w))+sum(sum(abs(W)))));     loss[ncol(loss)];     w_2 = w_1;     w_1 = w;     W_2 = W_1;     W_1 = W;     if (k>1 && abs(loss[ncol(loss)]-loss[ncol(loss)-1])/abs(loss[ncol(loss)])<0.001)# || (loss(end)<0))     break;   }   return(list(w,W)) } #figure; #plot(loss); ################## computeGradient =function(X,y,d,p,alpha,beta,S,lambda1,lambda2,w,W, type,M){ N = nrow(X); D = ncol(X); #M = length(unique(d)); g_w = matrix(data = 0,nrow = nrow((w)),ncol = ncol(w)) g_W = matrix(data = 0,nrow = nrow(W),ncol = ncol(W)) g_w <- Matrix(g_w, sparse = TRUE) g_W <- Matrix(g_W, sparse = TRUE) if (type=="ls"){ for (m in 1:M){ temp = (2*t(X[as.vector(d==m),]))%*% ((X[as.vector(d==m),]%*%(w+W[,m])-y[d==m])); g_w = g_w + temp; g_W[,m] = g_W[,m] + temp; } } for (m in 1:M){   #----------------##################### g_W[,m] = g_W[,m] + 4*beta*(sum(S[m,])*W[,m]-W%*%S[m,]); } g_w = g_w - alpha*p+(2*lambda1)*w; g_W = g_W + (2*lambda1)*W; return(list(g_w,g_W)) } ################################## computeLoss<- function(X,y,d,p,alpha,beta,S,lambda1,lambda2,w,W, type,M){ N = nrow(X); D = ncol(X); #M = length(unique(d)); f = 0; if (type=="ls") { for (m in 1:M)   f = f+norm_vec((X[as.vector(d==m),]%*%(w+W[,m])-y[d==m]))^2  # sum((X[d==m,]%*%(w+W[,m])-y[d=m])^2); } f = f-alpha*t(p)%*%w; f = f+lambda1*(sum(w^2)+sum(sum(W^2))); for (i in 1:M){     for (j in 1:M)         f = f+beta*S[i,j]*sum((W[,i]-W[,j])^2); } f } norm_vec <- function(x) sqrt(sum(x^2))
system.time(MultiDomain( X, y, d, p, alpha, beta, S, lambda1, lambda2, type))MultiDomain  = function(X,y,d,p,alpha,beta,S,lambda1,lambda2, type) {   D = ncol(X);   M = length(unique(d));   w = matrix(data = 0,nrow = D,ncol = 1)   W = matrix(data = 0,nrow = D,ncol = M)  # X <- Matrix(X, sparse = TRUE)   #y <- Matrix(y, sparse = TRUE) # d <- Matrix(d, sparse = TRUE) #  p <- Matrix(p, sparse = TRUE) #  S <- Matrix(S, sparse = TRUE) #  W <- Matrix(W, sparse = TRUE) #  w <- Matrix(w, sparse = TRUE)   w_2 = w;   w_1 = w;   W_2 = W;   W_1 = W;   f = computeLoss(X, y, d, p, alpha, beta, S, lambda1, lambda2, w, W, type,M)+lambda2*(sum(abs(w))+sum(sum(abs(W))));   loss=f;   k = 0;   gamma = 1;   while  (k<1000 && gamma>10^(-40))   {     print(k)     k=k+1;     a = k/(k+3);     y_w = (1+a)*w_1 - a*w_2;     #print(y_w)     y_W = (1+a)*W_1 - a*W_2;     output=computeGradient(X, y, d, p, alpha, beta, S, lambda1, lambda2, y_w, y_W, type,M);     g_w=output[[1]]     g_W=output[[2]]     w = y_w - gamma*g_w;     W = y_W - gamma*g_W;     w[abs(w)<=lambda2*gamma]=0;     W[abs(W)<=lambda2*gamma]=0;     y1 = sign(w);     y2 = abs(w)-lambda2*gamma;     w = y1*y2;     y1 = sign(W);     y2 = abs(W)-lambda2*gamma;     W = y1*y2;     ##I was here     f = computeLoss(X,y,d,p,alpha,beta,S,lambda1,lambda2,w,W, type,M);     f_y = computeLoss(X,y,d,p,alpha,beta,S,lambda1,lambda2,y_w,y_W, type,M);     f_lip = f_y + t(g_w)%*%(w-y_w) + 1/2/gamma*norm_vec((w-y_w))^2;     for (m in 1:M)     {       f_lip = f_lip+t(g_W[,m])%*%(W[,m]-y_W[,m])+1/2/gamma*norm_vec((W[,m]-y_W[,m]))^2;       #####     }     iter = 0;     while ((f>f_lip)[1] && gamma>10^(-40))     {       iter = iter+1;       gamma = gamma/2;       w = y_w - gamma*g_w;       W = y_W - gamma*g_W;       w[abs(w)<=lambda2*gamma]=0;       W[abs(W)<=lambda2*gamma]=0;       y1 = sign(w);       y2 = abs(w)-lambda2*gamma;       w = y1*y2;       y1 = sign(W);       y2 = abs(W)-lambda2*gamma;       W = y1*y2;       f = computeLoss(X,y,d,p,alpha,beta,S,lambda1,lambda2,w,W, type,M);       f_lip = f_y + t(g_w)%*%(w-y_w) + 1/2/gamma*norm_vec((w-y_w))^2;       for (m in 1:M){         f_lip = f_lip+t(g_W[,m])%*%(W[,m]-y_W[,m])+1/2/gamma*norm_vec((W[,m]-y_W[,m]))^2;       }     }     loss = cbind(loss, f+lambda2*(sum(abs(w))+sum(sum(abs(W)))));     loss[ncol(loss)];     w_2 = w_1;     w_1 = w;     W_2 = W_1;     W_1 = W;     if (k>1 && abs(loss[ncol(loss)]-loss[ncol(loss)-1])/abs(loss[ncol(loss)])<0.001)# || (loss(end)<0))     break;   }   return(list(w,W)) } #figure; #plot(loss); ################## computeGradient =function(X,y,d,p,alpha,beta,S,lambda1,lambda2,w,W, type,M){ N = nrow(X); D = ncol(X); #M = length(unique(d)); g_w = matrix(data = 0,nrow = nrow((w)),ncol = ncol(w)) g_W = matrix(data = 0,nrow = nrow(W),ncol = ncol(W)) g_w <- Matrix(g_w, sparse = TRUE) g_W <- Matrix(g_W, sparse = TRUE) if (type=="ls"){ for (m in 1:M){ temp = (2*t(X[as.vector(d==m),]))%*% ((X[as.vector(d==m),]%*%(w+W[,m])-y[d==m])); g_w = g_w + temp; g_W[,m] = g_W[,m] + temp; } } for (m in 1:M){   #----------------##################### g_W[,m] = g_W[,m] + 4*beta*(sum(S[m,])*W[,m]-W%*%S[m,]); } g_w = g_w - alpha*p+(2*lambda1)*w; g_W = g_W + (2*lambda1)*W; return(list(g_w,g_W)) } ################################## computeLoss<- function(X,y,d,p,alpha,beta,S,lambda1,lambda2,w,W, type,M){ N = nrow(X); D = ncol(X); #M = length(unique(d)); f = 0; if (type=="ls") { for (m in 1:M)   f = f+norm_vec((X[as.vector(d==m),]%*%(w+W[,m])-y[d==m]))^2  # sum((X[d==m,]%*%(w+W[,m])-y[d=m])^2); } f = f-alpha*t(p)%*%w; f = f+lambda1*(sum(w^2)+sum(sum(W^2))); for (i in 1:M){     for (j in 1:M)         f = f+beta*S[i,j]*sum((W[,i]-W[,j])^2); } f } norm_vec <- function(x) sqrt(sum(x^2))
MultiDomain  = function(X,y,d,p,alpha,beta,S,lambda1,lambda2, type) {   D = ncol(X);   M = length(unique(d));   w = matrix(data = 0,nrow = D,ncol = 1)   W = matrix(data = 0,nrow = D,ncol = M)  # X <- Matrix(X, sparse = TRUE)   #y <- Matrix(y, sparse = TRUE) # d <- Matrix(d, sparse = TRUE) #  p <- Matrix(p, sparse = TRUE) #  S <- Matrix(S, sparse = TRUE) #  W <- Matrix(W, sparse = TRUE) #  w <- Matrix(w, sparse = TRUE)   w_2 = w;   w_1 = w;   W_2 = W;   W_1 = W;   f = computeLoss(X, y, d, p, alpha, beta, S, lambda1, lambda2, w, W, type,M)+lambda2*(sum(abs(w))+sum(sum(abs(W))));   loss=f;   k = 0;   gamma = 1;   while  (k<1000 && gamma>10^(-40))   {     print(k)     k=k+1;     a = k/(k+3);     y_w = (1+a)*w_1 - a*w_2;     #print(y_w)     y_W = (1+a)*W_1 - a*W_2;     output=computeGradient(X, y, d, p, alpha, beta, S, lambda1, lambda2, y_w, y_W, type,M);     g_w=output[[1]]     g_W=output[[2]]     w = y_w - gamma*g_w;     W = y_W - gamma*g_W;     w[abs(w)<=lambda2*gamma]=0;     W[abs(W)<=lambda2*gamma]=0;     y1 = sign(w);     y2 = abs(w)-lambda2*gamma;     w = y1*y2;     y1 = sign(W);     y2 = abs(W)-lambda2*gamma;     W = y1*y2;     ##I was here     f = computeLoss(X,y,d,p,alpha,beta,S,lambda1,lambda2,w,W, type,M);     f_y = computeLoss(X,y,d,p,alpha,beta,S,lambda1,lambda2,y_w,y_W, type,M);     f_lip = f_y + t(g_w)%*%(w-y_w) + 1/2/gamma*norm_vec((w-y_w))^2;     for (m in 1:M)     {       f_lip = f_lip+t(g_W[,m])%*%(W[,m]-y_W[,m])+1/2/gamma*norm_vec((W[,m]-y_W[,m]))^2;       #####     }     iter = 0;     while ((f>f_lip)[1] && gamma>10^(-40))     {       iter = iter+1;       gamma = gamma/2;       w = y_w - gamma*g_w;       W = y_W - gamma*g_W;       w[abs(w)<=lambda2*gamma]=0;       W[abs(W)<=lambda2*gamma]=0;       y1 = sign(w);       y2 = abs(w)-lambda2*gamma;       w = y1*y2;       y1 = sign(W);       y2 = abs(W)-lambda2*gamma;       W = y1*y2;       f = computeLoss(X,y,d,p,alpha,beta,S,lambda1,lambda2,w,W, type,M);       f_lip = f_y + t(g_w)%*%(w-y_w) + 1/2/gamma*norm_vec((w-y_w))^2;       for (m in 1:M){         f_lip = f_lip+t(g_W[,m])%*%(W[,m]-y_W[,m])+1/2/gamma*norm_vec((W[,m]-y_W[,m]))^2;       }     }     loss = cbind(loss, f+lambda2*(sum(abs(w))+sum(sum(abs(W)))));     loss[ncol(loss)];     w_2 = w_1;     w_1 = w;     W_2 = W_1;     W_1 = W;     if (k>1 && abs(loss[ncol(loss)]-loss[ncol(loss)-1])/abs(loss[ncol(loss)])<0.001)# || (loss(end)<0))     break;   }   return(list(w,W)) } #figure; #plot(loss); ################## computeGradient =function(X,y,d,p,alpha,beta,S,lambda1,lambda2,w,W, type,M){ N = nrow(X); D = ncol(X); #M = length(unique(d)); g_w = matrix(data = 0,nrow = nrow((w)),ncol = ncol(w)) g_W = matrix(data = 0,nrow = nrow(W),ncol = ncol(W)) g_w <- Matrix(g_w, sparse = TRUE) g_W <- Matrix(g_W, sparse = TRUE) if (type=="ls"){ for (m in 1:M){ temp = (2*t(X[as.vector(d==m),]))%*% ((X[as.vector(d==m),]%*%(w+W[,m])-y[d==m])); g_w = g_w + temp; g_W[,m] = g_W[,m] + temp; } } for (m in 1:M){   #----------------##################### g_W[,m] = g_W[,m] + 4*beta*(sum(S[m,])*W[,m]-W%*%S[m,]); } g_w = g_w - alpha*p+(2*lambda1)*w; g_W = g_W + (2*lambda1)*W; return(list(g_w,g_W)) } ################################## computeLoss<- function(X,y,d,p,alpha,beta,S,lambda1,lambda2,w,W, type,M){ N = nrow(X); D = ncol(X); #M = length(unique(d)); f = 0; if (type=="ls") { for (m in 1:M)   f = f+norm_vec((X[as.vector(d==m),]%*%(w+W[,m])-y[d==m]))^2  # sum((X[d==m,]%*%(w+W[,m])-y[d=m])^2); } f = f-alpha*t(p)%*%w; f = f+lambda1*(sum(w^2)+sum(sum(W^2))); for (i in 1:M){     for (j in 1:M)         f = f+beta*S[i,j]*sum((W[,i]-W[,j])^2); } f } norm_vec <- function(x) sqrt(sum(x^2))
MultiDomain  = function(X,y,d,p,alpha,beta,S,lambda1,lambda2, type) {   D = ncol(X);   M = length(unique(d));   w = matrix(data = 0,nrow = D,ncol = 1)   W = matrix(data = 0,nrow = D,ncol = M)  # X <- Matrix(X, sparse = TRUE)   #y <- Matrix(y, sparse = TRUE) # d <- Matrix(d, sparse = TRUE) #  p <- Matrix(p, sparse = TRUE) #  S <- Matrix(S, sparse = TRUE) #  W <- Matrix(W, sparse = TRUE) #  w <- Matrix(w, sparse = TRUE)   w_2 = w;   w_1 = w;   W_2 = W;   W_1 = W;   f = computeLoss(X, y, d, p, alpha, beta, S, lambda1, lambda2, w, W, type,M)+lambda2*(sum(abs(w))+sum(sum(abs(W))));   loss=f;   k = 0;   gamma = 1;   while  (k<1000 && gamma>10^(-40))   {     print(k)     k=k+1;     a = k/(k+3);     y_w = (1+a)*w_1 - a*w_2;     #print(y_w)     y_W = (1+a)*W_1 - a*W_2;     output=computeGradient(X, y, d, p, alpha, beta, S, lambda1, lambda2, y_w, y_W, type,M);     g_w=output[[1]]     g_W=output[[2]]     w = y_w - gamma*g_w;     W = y_W - gamma*g_W;     w[abs(w)<=lambda2*gamma]=0;     W[abs(W)<=lambda2*gamma]=0;     y1 = sign(w);     y2 = abs(w)-lambda2*gamma;     w = y1*y2;     y1 = sign(W);     y2 = abs(W)-lambda2*gamma;     W = y1*y2;     ##I was here     f = computeLoss(X,y,d,p,alpha,beta,S,lambda1,lambda2,w,W, type,M);     f_y = computeLoss(X,y,d,p,alpha,beta,S,lambda1,lambda2,y_w,y_W, type,M);     f_lip = f_y + t(g_w)%*%(w-y_w) + 1/2/gamma*norm_vec((w-y_w))^2;     for (m in 1:M)     {       f_lip = f_lip+t(g_W[,m])%*%(W[,m]-y_W[,m])+1/2/gamma*norm_vec((W[,m]-y_W[,m]))^2;       #####     }     iter = 0;     while ((f>f_lip)[1] && gamma>10^(-40))     {       iter = iter+1;       gamma = gamma/2;       w = y_w - gamma*g_w;       W = y_W - gamma*g_W;       w[abs(w)<=lambda2*gamma]=0;       W[abs(W)<=lambda2*gamma]=0;       y1 = sign(w);       y2 = abs(w)-lambda2*gamma;       w = y1*y2;       y1 = sign(W);       y2 = abs(W)-lambda2*gamma;       W = y1*y2;       f = computeLoss(X,y,d,p,alpha,beta,S,lambda1,lambda2,w,W, type,M);       f_lip = f_y + t(g_w)%*%(w-y_w) + 1/2/gamma*norm_vec((w-y_w))^2;       for (m in 1:M){         f_lip = f_lip+t(g_W[,m])%*%(W[,m]-y_W[,m])+1/2/gamma*norm_vec((W[,m]-y_W[,m]))^2;       }     }     loss = cbind(loss, f+lambda2*(sum(abs(w))+sum(sum(abs(W)))));     loss[ncol(loss)];     w_2 = w_1;     w_1 = w;     W_2 = W_1;     W_1 = W;     if (k>1 && abs(loss[ncol(loss)]-loss[ncol(loss)-1])/abs(loss[ncol(loss)])<0.001)# || (loss(end)<0))     break;   }   return(list(w,W)) } #figure; #plot(loss); ################## computeGradient =function(X,y,d,p,alpha,beta,S,lambda1,lambda2,w,W, type,M){ N = nrow(X); D = ncol(X); #M = length(unique(d)); g_w = matrix(data = 0,nrow = nrow((w)),ncol = ncol(w)) g_W = matrix(data = 0,nrow = nrow(W),ncol = ncol(W)) g_w <- Matrix(g_w, sparse = TRUE) g_W <- Matrix(g_W, sparse = TRUE) if (type=="ls"){ for (m in 1:M){ temp = (2*t(X[as.vector(d==m),]))%*% ((X[as.vector(d==m),]%*%(w+W[,m])-y[d==m])); g_w = g_w + temp; g_W[,m] = g_W[,m] + temp; } } for (m in 1:M){   #----------------##################### g_W[,m] = g_W[,m] + 4*beta*(sum(S[m,])*W[,m]-W%*%S[m,]); } g_w = g_w - alpha*p+(2*lambda1)*w; g_W = g_W + (2*lambda1)*W; return(list(g_w,g_W)) } ################################## computeLoss<- function(X,y,d,p,alpha,beta,S,lambda1,lambda2,w,W, type,M){ N = nrow(X); D = ncol(X); #M = length(unique(d)); f = 0; if (type=="ls") { for (m in 1:M)   f = f+norm_vec((X[as.vector(d==m),]%*%(w+W[,m])-y[d==m]))^2  # sum((X[d==m,]%*%(w+W[,m])-y[d=m])^2); } f = f-alpha*t(p)%*%w; f = f+lambda1*(sum(w^2)+sum(sum(W^2))); for (i in 1:M){     for (j in 1:M)         f = f+beta*S[i,j]*sum((W[,i]-W[,j])^2); } f } norm_vec <- function(x) sqrt(sum(x^2))
system.time(MultiDomain( X, y, d, p, alpha, beta, S, lambda1, lambda2, type))
install.packages("rpud")
rtvs::debug_source("E:/CMSA/Main/script.R")
rtvs::debug_source("E:/CMSA/Main/script.R")
rtvs::debug_source("E:/CMSA/Main/script.R")
rtvs::debug_source("E:/CMSA/Main/script.R")
rtvs::debug_source("E:/CMSA/Main/script.R")
nrows(X)
nrow(X)
ncol(X)
diag(1000)
